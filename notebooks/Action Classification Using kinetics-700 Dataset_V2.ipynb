{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1ycDuyQQVDX"
      },
      "source": [
        "# **Action Classification Using kinetics-700 Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4StGz9ynOEL6"
      },
      "source": [
        "# Load video data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "incZngmV8tUA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRhKvc5NM2P"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjI3AaaO16bd"
      },
      "outputs": [],
      "source": [
        "# The way this tutorial uses the `TimeDistributed` layer requires TF>=2.10\n",
        "# !pip install -U \"tensorflow>=2.10.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RYQIJ9C6BVH"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "from IPython import display\n",
        "from urllib import request\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbhwWLLM7FXo"
      },
      "source": [
        "## Download the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1OtIHA6rGRP"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pos_2_2ZfFEy"
      },
      "outputs": [],
      "source": [
        "# !pip install split_folders\n",
        "# import splitfolders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwEL1lvreh-Q"
      },
      "outputs": [],
      "source": [
        "# splitfolders.ratio('/content/drive/MyDrive/videos_150', output='/content/drive/MyDrive/vids_150_split', seed=42, ratio=(0.8,0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a61zZGgdam5V"
      },
      "outputs": [],
      "source": [
        "# splitfolders.ratio('/content/drive/MyDrive/vids_150_split/train', output='/content/drive/MyDrive/data', seed=42, ratio=(0.8,0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmkgnKB782gX"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# shutil.move('/content/drive/MyDrive/vids_150_split/test', '/content/drive/MyDrive/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj2QZKbp57D7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4uslY4dScyu"
      },
      "source": [
        "## Create frames from each video file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1vvyT0F7JAZ"
      },
      "source": [
        "The `frames_from_video_file` function splits the videos into frames, reads a randomly chosen span of `n_frames` out of a video file, and returns them as a NumPy `array`.\n",
        "To reduce memory and computation overhead, choose a **small** number of frames. In addition, pick the **same** number of frames from each video, which makes it easier to work on batches of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNBCiV3bMzpD"
      },
      "outputs": [],
      "source": [
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "    \n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded. \n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ujLDC9G7JyE"
      },
      "outputs": [],
      "source": [
        "def frames_from_video_file(video_path, n_frames, output_size = (128,128), frame_step = 15):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))  \n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "  need_length = 1 + (n_frames - 1) * frame_step\n",
        "\n",
        "  if need_length > video_length:\n",
        "    start = 0\n",
        "  else:\n",
        "    max_start = video_length - need_length\n",
        "    start = random.randint(0, max_start + 1)\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "  ret, frame = src.read()\n",
        "  result.append(format_frames(frame, output_size))\n",
        "\n",
        "  for _ in range(n_frames - 1):\n",
        "    for _ in range(frame_step):\n",
        "      ret, frame = src.read()\n",
        "    if ret:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      result.append(np.zeros_like(result[0]))\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVmfLTlw7Ues"
      },
      "outputs": [],
      "source": [
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label. \n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames. \n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.mp4'))\n",
        "    classes = [p.parent.name for p in video_paths] \n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "\n",
        "    for path, name in pairs:\n",
        "      video_frames = frames_from_video_file(path, self.n_frames) \n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsvhPIkpzx-r"
      },
      "source": [
        "Test out the `FrameGenerator` object before wrapping it as a TensorFlow Dataset object. Moreover, for the training dataset, ensure you enable training mode so that the data will be shuffled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix4rXZK1LqwD"
      },
      "outputs": [],
      "source": [
        "download_dir = pathlib.Path('/content/drive/MyDrive/data')\n",
        "data={}\n",
        "for f in os.listdir('/content/drive/MyDrive/data'):\n",
        "  data[f]=download_dir / f\n",
        "  print(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdByiavA0hMl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5jwagZxzxOf"
      },
      "outputs": [],
      "source": [
        "fg = FrameGenerator(data['train'], 10, training=True)\n",
        "\n",
        "frames, label = next(fg())\n",
        "\n",
        "print(f\"Shape: {frames.shape}\")\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH9SsK0rLq4q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7MRRFSks7l1"
      },
      "source": [
        "Finally, create a TensorFlow data input pipeline. This pipeline that you create from the generator object allows you to feed in data to your deep learning model. In this video pipeline, each element is a single set of frames and its associated label. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM4NboJr7ck4"
      },
      "outputs": [],
      "source": [
        "# Create the training set\n",
        "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(data['train'], 10, training=True),\n",
        "                                          output_signature = output_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oF_8m8IZvcY"
      },
      "source": [
        "Check to see that the labels are shuffled. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XYVmsgiZsJD"
      },
      "outputs": [],
      "source": [
        "for frames, labels in train_ds.take(10):\n",
        "  print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi8-WkOkEXw5"
      },
      "outputs": [],
      "source": [
        "# Create the validation set\n",
        "val_ds = tf.data.Dataset.from_generator(FrameGenerator(data['val'], 10),\n",
        "                                        output_signature = output_signature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkZBTOAEcpUi"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(data['test'], 10),\n",
        "                                        output_signature = output_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIrFpUIxvTLe"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "Use buffered prefetching such that you can yield data from the disk without having I/O become blocking. Two important functions to use while loading data are:\n",
        "\n",
        "* `Dataset.cache`: keeps the sets of frames in memory after they're loaded off the disk during the first epoch. This function ensures that the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "\n",
        "* `Dataset.prefetch`: overlaps data preprocessing and model execution while training.\n",
        "Refer to [Better performance with the `tf.data`](https://www.tensorflow.org/guide/data_performance) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSxjFtxAvY3_"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp2Qc6XSFmeB"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(8)\n",
        "val_ds = val_ds.batch(8)\n",
        "test_ds = test_ds.batch(8)\n",
        "\n",
        "train_frames, train_labels = next(iter(train_ds))\n",
        "print(f'Shape of training set of frames: {train_frames.shape}')\n",
        "print(f'Shape of training labels: {train_labels.shape}')\n",
        "\n",
        "val_frames, val_labels = next(iter(val_ds))\n",
        "print(f'Shape of validation set of frames: {val_frames.shape}')\n",
        "print(f'Shape of validation labels: {val_labels.shape}')\n",
        "\n",
        "test_frames, test_labels = next(iter(test_ds))\n",
        "print(f'Shape of test set of frames: {test_frames.shape}')\n",
        "print(f'Shape of test labels: {test_labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7CoWL90Nklw"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZKFZL9e7h6X"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA0AJ5jyM8gt"
      },
      "outputs": [],
      "source": [
        "net = tf.keras.applications.EfficientNetV2B0(include_top = False)\n",
        "net.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(scale=255),\n",
        "    tf.keras.layers.TimeDistributed(net),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.GlobalAveragePooling3D()\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAqwB0h6tA7g"
      },
      "outputs": [],
      "source": [
        "results=model.fit(train_ds, \n",
        "          epochs = 15,#+40\n",
        "          validation_data = val_ds\n",
        "          ,\n",
        "          # callbacks = tf.keras.callbacks.EarlyStopping(patience = 4, monitor = 'val_loss')\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t67VEg4z1HW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1zfWY_5KSom"
      },
      "outputs": [],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEHG7dv1tKeA"
      },
      "outputs": [],
      "source": [
        "print(results.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k3QPltVzU7A"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/kinetics_model_efficinetv2.h5\")\n",
        "\n",
        "# Model class must be defined somewhere\n",
        "model= tf.keras.models.load_model(\"/content/drive/MyDrive/kinetics_model_efficinetv2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25lMwN3yzUcj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LltdBxxDNoFx"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PSGdk9NtKeB"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIlwUn0BtKeB"
      },
      "outputs": [],
      "source": [
        "def get_actual_predicted_labels(dataset):\n",
        "  \"\"\"\n",
        "    Create a list of actual ground truth values and the predictions from the model.\n",
        "\n",
        "    Args:\n",
        "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
        "\n",
        "    Return:\n",
        "      Ground truth and predicted values for a particular dataset.\n",
        "  \"\"\"\n",
        "  actual = [labels for _, labels in dataset.unbatch()]\n",
        "  predicted = model.predict(dataset)\n",
        "\n",
        "  actual = tf.stack(actual, axis=0)\n",
        "  predicted = tf.concat(predicted, axis=0)\n",
        "  predicted = tf.argmax(predicted, axis=1)\n",
        "\n",
        "  return actual, predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtdI6iO6tKeC"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
        "  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(12, 12)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9Yqb_y3tKeC"
      },
      "outputs": [],
      "source": [
        "fg = FrameGenerator(data['train'], 8, training = True)\n",
        "label_names = list(fg.class_ids_for_name.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozWzh51NNvbw"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubshaq2TtKeC"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "actual, predicted = get_actual_predicted_labels(test_ds)\n",
        "plot_confusion_matrix(actual, predicted, label_names, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr_T3h62JAE0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8n1s75D6sL8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYfbIExI6sIJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOlsT_XN6r6g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEgc7Elm_0JQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "2c1d53054155cd49b2a96c2bfed63d0e720c7c155830a1fd4135e6a26f0aebed"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
